{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auto Configuration Succeed!, Using database /home/tzhouaq/offline-moo/off_moo_bench/problem/mo_nas/database.\n",
      "Configuration Succeed!\n",
      "Auto Configuration Succeed!, Using database /home/tzhouaq/offline-moo/off_moo_bench/problem/mo_nas/database.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"  # 使 GPU 0 和 1 可见\n",
    "import logging\n",
    "import numpy as np\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "from pathlib import Path\n",
    "from typing import Callable, Optional, Sequence, Union\n",
    "from pymoo.indicators.gd import GD\n",
    "from pymoo.indicators.gd_plus import GDPlus\n",
    "from pymoo.indicators.igd import IGD\n",
    "from pymoo.indicators.igd_plus import IGDPlus\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "BASE_PATH = os.path.join(\n",
    "   '/home/tzhouaq/offline-moo/'\n",
    ")\n",
    "sys.path.append(BASE_PATH)\n",
    "CONDITIONAL_TASKS = []\n",
    "# sys.path.append(os.path.join(BASE_PATH, 'off_moo_baselines'))\n",
    "import off_moo_bench as ob\n",
    "sys.path.append(os.path.join(BASE_PATH, 'off_moo_baselines'))\n",
    "from mo_solver.ddom.design_baselines.diff.trainer import RvSDataModule\n",
    "from mo_solver.ddom.design_baselines.diff.nets import (\n",
    "    DiffusionTest, DiffusionScore, Swish\n",
    ")\n",
    "from mo_solver.ddom.design_baselines.diff.lib.sdes import (\n",
    "    PluginReverseSDE, VariancePreservingSDE, UnconditionPluginReverseSDE\n",
    ")\n",
    "from mo_solver.ddom.design_baselines.diff.forward import ForwardModel\n",
    "from utils import set_seed\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All config: {'results_dir': './results', 'model_save_dir': './model', 'use_wandb': False, 'run_type': 'train', 'seed': 1000, 'retrain_model': False, 'num_solutions': 256, 'solver_n_gen': 50, 'solver_init_method': 'nds', 'model': 'MOBO', 'train_mode': 'Vallina', 'task': 're35', 'n_epochs': 10, 'data_pruning': False, 'permutation_n_gen': 200, 'sequence_n_gen': 200, 'train_gp_data_size': 256, 'normalize_xs': True, 'normalize_ys': True, 'to_logits': False, 'record_hist': True}\n"
     ]
    }
   ],
   "source": [
    "from utils import process_args \n",
    "sys.argv = ['--model=MOBO', '--train_mode=Vallina','--task=re35','--use_wandb=False','--n_epochs=10','--retrain_model=False','--seed=1000']\n",
    "config = process_args(return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# toy example\n",
    "# te1 \n",
    "\n",
    "# Synthetic Functions \n",
    "# \"dtlz1 dtlz2 dtlz3 dtlz4 dtlz5 dtlz6 dtlz7 zdt1 zdt2 zdt3 zdt4 zdt6 vlmop1 vlmop2 vlmop3 omnitest\"\n",
    "\n",
    "# RE\n",
    "# \"re21 re22 re23 re24 re25 re31 re32 re33 re34 re35 re36 re37 re41 re42 re61\"\n",
    "\n",
    "# MO-NAS\n",
    "# \"nb201_test c10mop1 c10mop2 c10mop3 c10mop4 c10mop5 c10mop6 c10mop7 c10mop8 c10mop9 in1kmop1 in1kmop2 in1kmop3 in1kmop4 in1kmop5 in1kmop6 in1kmop7 in1kmop8 in1kmop9\"\n",
    "\n",
    "# MORL\n",
    "# \"mo_hopper_v2 mo_swimmer_v2\"\n",
    "\n",
    "# MOCO \n",
    "# \"bi_tsp_20 bi_tsp_50 bi_tsp_100 bi_tsp_500 tri_tsp_20 tri_tsp_50 tri_tsp_100 bi_cvrp_20 bi_cvrp_50 bi_cvrp_100 bi_kp_50 bi_kp_100 bi_kp_200\"\n",
    "\n",
    "# Scientific Design\n",
    "# \"zinc regex rfp molecule\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils import process_args \n",
    "# sys.argv = ['--model=End2End', '--train_mode=Vallina','--task=re21','--use_wandb=False','--n_epochs=10','--retrain_model=False','--seed=1000']\n",
    "# config = process_args(return_dict=True)\n",
    "\n",
    "# results_dir = os.path.join('/home/tzhouaq/offline-moo/', \"results\")\n",
    "# model_save_dir = os.path.join('/home/tzhouaq/offline-moo/', \"model\")\n",
    " \n",
    "# config[\"results_dir\"] = results_dir\n",
    "# config[\"model_save_dir\"] = model_save_dir\n",
    "# config[\"data_pruning\"] = True\n",
    "# config['data_preserved_ratio']= 1.0\n",
    "# config['hidden_size']=2048\n",
    "# config['inverse_lr']=1e-4\n",
    "# # config['batch_size']= 16\n",
    "# config['inverse_lr_decay']=0.98\n",
    "# config['n_epochs']= 200\n",
    "\n",
    "# config['simple_clip']=True\n",
    "# config['debais']=True\n",
    "# config[\"record_hist\"]=False\n",
    "# config['dropout']=0. \n",
    "# config['augment']=True\n",
    "# config['condition_training']=False\n",
    "# config['model_ckpt'] = None \n",
    "# # config['normalize_xs'] = False\n",
    "# # config['normalize_ys'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys \n",
    "import wandb \n",
    "import torch \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import datetime \n",
    "import json \n",
    "from copy import deepcopy\n",
    "\n",
    "# BASE_PATH = os.path.join(\n",
    "#     os.path.dirname(os.path.abspath(__file__)),\n",
    "#     \"..\", \"..\"\n",
    "# )\n",
    "# sys.path.append(BASE_PATH)\n",
    "\n",
    "import off_moo_bench as ob\n",
    "from pymoo.algorithms.moo.nsga2 import NSGA2\n",
    "from utils import set_seed, get_quantile_solutions\n",
    "from off_moo_baselines.data import get_dataloader\n",
    "from off_moo_baselines.mobo import get_mobo_solver\n",
    "from off_moo_baselines.mobo.mobo_utils import tkwargs\n",
    "from off_moo_bench.task_set import *\n",
    "from off_moo_bench.evaluation.metrics import hv\n",
    "from off_moo_bench.evaluation.plot import plot_y\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run(config: dict):\n",
    "    if config[\"task\"] in ALLTASKSDICT.keys():\n",
    "        config[\"task\"] = ALLTASKSDICT[config[\"task\"]]\n",
    "    \n",
    "    results_dir = os.path.join(config['results_dir'], \n",
    "                               f\"{config['model']}-{config['train_mode']}-{config['task']}\")\n",
    "    config[\"results_dir\"] = results_dir \n",
    "    \n",
    "    ts = datetime.datetime.utcnow() + datetime.timedelta(hours=+8)\n",
    "    ts_name = f\"-ts-{ts.year}-{ts.month}-{ts.day}_{ts.hour}-{ts.minute}-{ts.second}\"\n",
    "    run_name = f\"{config['model']}-{config['train_mode']}-seed{config['seed']}-{config['task']}\"\n",
    "    \n",
    "    logging_dir = os.path.join(config['results_dir'], run_name + ts_name)\n",
    "    os.makedirs(logging_dir, exist_ok=True)\n",
    "\n",
    "    if config['use_wandb']:\n",
    "        if 'wandb_api' in config.keys():\n",
    "            wandb.login(key=config['wandb_api'])\n",
    "\n",
    "        wandb.init(\n",
    "            project=\"Offline-MOO\",\n",
    "            name=run_name + ts_name,\n",
    "            config=config,\n",
    "            group=f\"{config['model']}-{config['train_mode']}\",\n",
    "            job_type=config['run_type'],\n",
    "            mode=\"online\",\n",
    "            dir=os.path.join(config['results_dir'], '..')\n",
    "        )\n",
    "    \n",
    "    with open(os.path.join(logging_dir, \"params.json\"), \"w\") as f:\n",
    "        json.dump(config, f, indent=4)\n",
    "\n",
    "    set_seed(config['seed'])\n",
    "\n",
    "    task = ob.make(config['task'])\n",
    "    pf = task.problem.get_pareto_front()\n",
    "    if config['normalize_ys']:\n",
    "        pf = task.normalize_y(pf)\n",
    "    X = task.x.copy()\n",
    "    y = task.y.copy()\n",
    "    \n",
    "    if config[\"data_pruning\"]:\n",
    "        X, y = task.get_N_non_dominated_solutions(\n",
    "            N=int(X.shape[0] * config[\"data_preserved_ratio\"]),\n",
    "            return_x=True, return_y=True\n",
    "        )\n",
    "    \n",
    "    X_test = task.x_test.copy()\n",
    "    y_test = task.y_test.copy()\n",
    "    \n",
    "    if config['to_logits']:\n",
    "        assert task.is_discrete \n",
    "        task.map_to_logits()\n",
    "        X = task.to_logits(X)\n",
    "        X_test = task.to_logits(X_test)\n",
    "    if config['normalize_xs']:\n",
    "        task.map_normalize_x()\n",
    "        X = task.normalize_x(X)\n",
    "        X_test = task.normalize_x(X_test)\n",
    "    if config['normalize_ys']:\n",
    "        task.map_normalize_y()\n",
    "        y = task.normalize_y(y)\n",
    "        y_test = task.normalize_y(y_test)\n",
    "    \n",
    "    if config['to_logits']:\n",
    "        data_size, n_dim, n_classes = tuple(X.shape)\n",
    "        X = X.reshape(-1, n_dim * n_classes)\n",
    "        X_test = X_test.reshape(-1, n_dim * n_classes)\n",
    "    else:\n",
    "        data_size, n_dim = tuple(X.shape)\n",
    "    n_obj = y.shape[1]\n",
    "        \n",
    "    model_save_dir = config['model_save_dir']\n",
    "    os.makedirs(model_save_dir, exist_ok=True)\n",
    "    \n",
    "    MOBO_Solver = get_mobo_solver(config[\"train_mode\"])\\\n",
    "        (\n",
    "            config=config,\n",
    "            X_init=torch.Tensor(X).to(**tkwargs),\n",
    "            Y_init=torch.Tensor(y).to(**tkwargs),\n",
    "            solver_kwargs={\n",
    "                \"ref_point\": torch.Tensor(1.1 * task.nadir_point).to(**tkwargs),\n",
    "                \"xl\": task.xl,\n",
    "                \"xu\": task.xu,\n",
    "            },\n",
    "            train_gp_data_size=config[\"train_gp_data_size\"],\n",
    "            output_size=config[\"num_solutions\"],\n",
    "            negate=True\n",
    "        )\n",
    "    \n",
    "    res_x = MOBO_Solver.run()\n",
    "    if config['to_logits']:\n",
    "        res_x = res_x.reshape(-1, n_dim, n_classes)\n",
    "    if config['normalize_xs']:\n",
    "        task.map_denormalize_x()\n",
    "        res_x = task.denormalize_x(res_x)\n",
    "    if config['to_logits']:\n",
    "        task.map_to_integers()\n",
    "        res_x = task.to_integers(res_x)\n",
    "    \n",
    "    res_y = task.predict(res_x)\n",
    "    visible_masks = np.ones(len(res_y))\n",
    "    visible_masks[np.where(np.logical_or(np.isinf(res_y), np.isnan(res_y)))[0]] = 0\n",
    "    visible_masks[np.where(np.logical_or(np.isinf(res_x), np.isnan(res_x)))[0]] = 0\n",
    "    res_x = res_x[np.where(visible_masks == 1)[0]]\n",
    "    res_y = res_y[np.where(visible_masks == 1)[0]]\n",
    "    \n",
    "    res_y_75_percent = get_quantile_solutions(res_y, 0.75)\n",
    "    res_y_50_percent = get_quantile_solutions(res_y, 0.50)\n",
    "    \n",
    "    nadir_point = task.nadir_point\n",
    "    if config['normalize_ys']:\n",
    "        res_y = task.normalize_y(res_y)\n",
    "        nadir_point = task.normalize_y(nadir_point)\n",
    "        res_y_50_percent = task.normalize_y(res_y_50_percent)\n",
    "        res_y_75_percent = task.normalize_y(res_y_75_percent)\n",
    "        \n",
    "    _, d_best = task.get_N_non_dominated_solutions(\n",
    "        N=6000, \n",
    "        return_x=False, return_y=True\n",
    "    )\n",
    "    \n",
    "    np.save(file=os.path.join(logging_dir, \"res_x.npy\"), arr=res_x)\n",
    "    np.save(file=os.path.join(logging_dir, \"res_y.npy\"), arr=res_y)\n",
    "    plot_y(res_y, save_dir=logging_dir, config=config,\n",
    "           nadir_point=nadir_point, d_best=d_best, pareto_front=pf,)\n",
    "        \n",
    "    d_best_hv = hv(nadir_point, d_best, config['task'])\n",
    "    hv_value = hv(nadir_point, res_y, config['task'])\n",
    "    hv_value_50_percentile = hv(nadir_point, res_y_50_percent, config['task'])\n",
    "    hv_value_75_percentile = hv(nadir_point, res_y_75_percent, config['task'])\n",
    "    \n",
    "    print(f\"Hypervolume (100th): {hv_value:4f}\")\n",
    "    print(f\"Hypervolume (75th): {hv_value_75_percentile:4f}\")\n",
    "    print(f\"Hypervolume (50th): {hv_value_50_percentile:4f}\")\n",
    "    print(f\"Hypervolume (D(best)): {d_best_hv:4f}\")\n",
    "\n",
    "\n",
    "    # 假设 pf 是你的帕累托前沿\n",
    "    ind_gd = GD(pf)\n",
    "    ind_gdp = GDPlus(pf)\n",
    "    ind_igd = IGD(pf)\n",
    "    ind_igdp = IGDPlus(pf)\n",
    "\n",
    "    # 计算 MOO的各种 指标\n",
    "    gd_plus_value = ind_gd.do(res_y)\n",
    "    gdp_plus_value = ind_gdp.do(res_y)\n",
    "    igd_value = ind_igd.do(res_y)\n",
    "    igd_plus_value = ind_igdp.do(res_y)\n",
    "\n",
    "    print(\"GD:\", gd_plus_value)\n",
    "    print(\"GD+:\", gdp_plus_value)\n",
    "    print(\"IGD:\", igd_value)\n",
    "    print(\"IGD+:\", igd_plus_value)\n",
    "    indicators_results = {\n",
    "        \"GD\": gd_plus_value,\n",
    "        \"GD+\": gd_plus_value,\n",
    "        \"IGD\": igd_value,\n",
    "        \"IGD+\": igd_plus_value,\n",
    "    }\n",
    "    hv_results = {\n",
    "        \"hypervolume/D(best)\": d_best_hv,\n",
    "        \"hypervolume/100th\": hv_value, \n",
    "        \"hypervolume/75th\": hv_value_75_percentile,\n",
    "        \"hypervolume/50th\": hv_value_50_percentile,\n",
    "        \"evaluation_step\": 1,\n",
    "    }\n",
    "\n",
    "    indicators_results.update(hv_results)\n",
    "\n",
    " \n",
    "    \n",
    "    df = pd.DataFrame([hv_results])\n",
    "    filename = os.path.join(logging_dir, \"hv_results.csv\")\n",
    "    df.to_csv(filename, index=False)\n",
    "    \n",
    "    if config[\"use_wandb\"]:\n",
    "        wandb.log(hv_results)\n",
    "\n",
    "    return hv_value, igd_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All config: {'results_dir': './results', 'model_save_dir': './model', 'use_wandb': False, 'run_type': 'train', 'seed': 1000, 'retrain_model': False, 'num_solutions': 256, 'solver_n_gen': 50, 'solver_init_method': 'nds', 'model': 'MOBO', 'train_mode': 'Vallina', 'task': 're35', 'n_epochs': 10, 'data_pruning': False, 'permutation_n_gen': 200, 'sequence_n_gen': 200, 'train_gp_data_size': 256, 'normalize_xs': True, 'normalize_ys': True, 'to_logits': False, 'record_hist': True}\n",
      "******************************************Seed40****************************************************\n"
     ]
    }
   ],
   "source": [
    "     \n",
    "\n",
    "from utils import process_args \n",
    "config = process_args(return_dict=True)\n",
    "\n",
    "results_dir = os.path.join(BASE_PATH, \"results\")\n",
    "model_save_dir = os.path.join(BASE_PATH, \"model\")\n",
    "\n",
    "config[\"results_dir\"] = results_dir\n",
    "config[\"model_save_dir\"] = model_save_dir\n",
    "\n",
    "config[\"train_gp_data_size\"] = 256\n",
    "\n",
    "solutions = []\n",
    "run_trials = 4\n",
    "seed_list = [40 ]#,41,42,43\n",
    "HV_list = []\n",
    "IGD_list = []\n",
    "for seed in seed_list:\n",
    "    print(f\"******************************************Seed{seed}****************************************************\")\n",
    "    config['seed'] = seed\n",
    "    hv_value, igd_value = run(config)\n",
    "    HV_list.append(hv_value)\n",
    "    IGD_list.append(igd_value)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Average Hypervolume: {np.mean(HV_list)}, std: {np.std(HV_list)}\")\n",
    "print(f\"Average IGD: {np.mean(IGD_list)}, std: {np.std(IGD_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "     \n",
    "\n",
    "from utils import process_args \n",
    "config = process_args(return_dict=True)\n",
    "\n",
    "results_dir = os.path.join(BASE_PATH, \"results\")\n",
    "model_save_dir = os.path.join(BASE_PATH, \"model\")\n",
    "\n",
    "config[\"results_dir\"] = results_dir\n",
    "config[\"model_save_dir\"] = model_save_dir\n",
    "\n",
    "config[\"train_gp_data_size\"] = 1\n",
    "\n",
    "solutions = []\n",
    "run_trials = 4\n",
    "HV_list = []\n",
    "IGD_list = []\n",
    "seed_list = [40 ]#,41,42,43\n",
    "for seed in seed_list:\n",
    "    print(f\"******************************************Seed{seed}****************************************************\")\n",
    "    config['seed'] = seed\n",
    "    hv_value, igd_value = run(config)\n",
    "    HV_list.append(hv_value)\n",
    "    IGD_list.append(igd_value)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Average Hypervolume: {np.mean(HV_list)}, std: {np.std(HV_list)}\")\n",
    "print(f\"Average IGD: {np.mean(IGD_list)}, std: {np.std(IGD_list)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "off-moo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
